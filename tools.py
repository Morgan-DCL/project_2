import json
import hjson
# from numba import njit
import logging
import os
import ast
import re

import numpy as np
import pandas as pd
import polars as pl

from colored import attr, fg
from cleaner import DataCleaner
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

clean = DataCleaner()

logging.basicConfig(
    format='%(asctime)s %(levelname)-8s %(message)s',
    level=logging.INFO,
    datefmt='%Y-%m-%d %H:%M:%S'
)

class MyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, set):
            return list(obj)
        else:
            return super(MyEncoder, self).default(obj)


def import_config():
    with open("config.hjson", "r") as fp:
        return hjson.load(fp)


def make_filepath(filepath: str) -> str:
    """
    Cr√©e un chemin de fichier si celui-ci n'existe pas d√©j√†.

    Cette fonction v√©rifie si le chemin de fichier sp√©cifi√© existe d√©j√†. Si ce n'est pas le cas, elle cr√©e le chemin de fichier.

    Param√®tres
    ----------
    filepath : str
        Le chemin de fichier √† cr√©er.

    Retourne
    -------
    str
        Le chemin de fichier sp√©cifi√©.

    Notes
    -----
    La fonction utilise la biblioth√®que os pour interagir avec le syst√®me d'exploitation.
    """

    # dirpath = os.path.dirname(filepath) if filepath[-1] != "/" else filepath
    if not os.path.exists(filepath):
        os.makedirs(filepath, exist_ok=True)
    return filepath


def hjson_dump(config: dict):
    with open("config.hjson", "w") as fp:
        hjson.dump(config, fp)


def get_download_link() -> dict:
    """
    Renvoie un dictionnaire contenant les noms des bases de donn√©es IMDB en
    tant que cl√©s et leurs liens de t√©l√©chargement respectifs en tant que valeurs.

    Returns
    -------
    dict
        Un dictionnaire o√π les cl√©s sont les noms des bases de
        donn√©es IMDB
        'name_basics',
        'title_akas',
        'title_basics',
        'title_episode',
        'title_principals',
        'title_ratings'
        et les valeurs sont les liens de t√©l√©chargement correspondants.
    """

    return {
        "name_basics" :     "https://datasets.imdbws.com/name.basics.tsv.gz",
        "title_akas" :      "https://datasets.imdbws.com/title.akas.tsv.gz",
        "title_basics" :    "https://datasets.imdbws.com/title.basics.tsv.gz",
        "title_episode" :   "https://datasets.imdbws.com/title.episode.tsv.gz",
        "title_principals": "https://datasets.imdbws.com/title.principals.tsv.gz",
        "title_ratings" :   "https://datasets.imdbws.com/title.ratings.tsv.gz"
    }


def get_tsv_files(folder_name: str) -> dict:
    """
    Obtient les chemins des fichiers TSV dans un dossier sp√©cifique.

    Param√®tres
    ----------
    folder_name : str
        Le nom du dossier contenant les fichiers TSV.

    Retourne
    -------
    dict
        Un dictionnaire contenant les noms des fichiers TSV
        comme cl√©s et leurs chemins respectifs comme valeurs.

    """
    return {
        "name_basics" : f"{folder_name}/name_basics.tsv",
        "title_ratings" : f"{folder_name}/title_ratings.tsv",
        "title_akas" : f"{folder_name}/title_akas.tsv",
        "title_basics" : f"{folder_name}/title_basics.tsv",
        "title_episode" : f"{folder_name}/title_episode.tsv",
        "title_principals" : f"{folder_name}/title_principals.tsv",
        "imdb_full" : f"clean_datasets/tmdb_updated.parquet",
    }

def replace_ids_with_titles(
    id_list: str,
    dict_titre: dict
) -> list:
    """
    Remplace les identifiants dans une liste par leurs titres correspondants √† partir d'un dictionnaire.

    Param√®tres
    ----------
    id_list : str
        Une cha√Æne de caract√®res repr√©sentant une liste d'identifiants.
        Les identifiants doivent √™tre s√©par√©s par des virgules et la liste doit √™tre entour√©e de crochets.

    dict_titre : dict
        Un dictionnaire o√π les cl√©s sont les identifiants et les valeurs sont les titres correspondants.

    Retourne
    -------
    list
        Une liste o√π chaque identifiant de la liste d'entr√©e a √©t√© remplac√© par
        son titre correspondant dans le dictionnaire.
        Si un identifiant ne se trouve pas dans le dictionnaire,
        il est laiss√© tel quel dans la liste de sortie.
    """
    if isinstance(id_list, str):
        id_list = ast.literal_eval(id_list)
    return [
        dict_titre.get(titre_id, titre_id)
        for titre_id in id_list
    ]

def if_tt_remove(id_list: list) -> list:
    """
    Effectue une op√©ration de filtrage sur une liste d'identifiants,
    en supprimant ceux qui commencent par "tt".

    Param√®tres
    ----------
    id_list : list
        Une liste de cha√Ænes de caract√®res repr√©sentant les identifiants √† filtrer.

    Retourne
    -------
    list
        Une nouvelle liste contenant uniquement les identifiants qui ne commencent pas par "tt".

    """

    return [
        t for t in id_list
        if not t.startswith("tt")
    ]

def transform_raw_datas(
    encryption: str = "polars",
    sep: str = ",",
    *datas: str
) -> list:
    """
    Transforme les donn√©es brutes en utilisant une m√©thode d'encryption sp√©cifique.

    Param√®tres
    ----------
    encryption : str, optional
        Le type d'encryption √† utiliser pour transformer les donn√©es. Par d√©faut, "polars".
    *datas : str
        Les donn√©es brutes √† transformer. Peut √™tre plusieurs cha√Ænes de caract√®res.

    Retourne
    -------
    list
        Une liste de donn√©es transform√©es.
        Chaque √©l√©ment de la liste correspond √† un ensemble de donn√©es transform√©.

    """
    return (
        [
            import_datasets(data, types=encryption, sep=sep) for
            data in datas if data
        ]
    )


def import_datasets(
    datas: str,
    types: str,
    sep: str = ",",
) -> pl.DataFrame:
    """
    Importe des ensembles de donn√©es √† l'aide de pandas ou polars.

    Parameters
    ----------
    datas : str
        Le chemin d'acc√®s complet au fichier de donn√©es √† importer.
    types : str
        Le type de biblioth√®que √† utiliser pour l'importation.
        Les options valides sont 'pandas', 'parquet' et 'polars'.
    sep : str, optional
        Le s√©parateur de colonnes √† utiliser lors de l'importation du fichier.
        Par d√©faut, il s'agit d'une virgule (',').

    Returns
    -------
    pl.DataFrame
        Un DataFrame contenant les donn√©es import√©es.

    Raises
    ------
    ValueError
        Si le type sp√©cifi√© n'est ni 'pandas', ni 'parquet', ni 'polars'.
    """
    data_name = datas.split("/")[-1]
    if types == "pandas":
        # logging.info(f"{fg('#ffa6c9')}{'üçÜ ! Cleaning porn movies ! üçÜ'}{attr(0)}")
        logging.info(f"{types.capitalize()} loaded ! Importing {data_name[:-4]}...")
        return pd.read_csv(datas, sep=sep, low_memory=False) #, encoding="iso-8859-1"
    if types == "parquet":
        # logging.info(f"{fg('#ffa6c9')}{'üçÜ ! Cleaning porn movies ! üçÜ'}{attr(0)}")
        logging.info(f"{types.capitalize()} loaded ! Importing {data_name[:-8]}...")
        return pd.read_parquet(datas)
    elif types == "polars":
        logging.info(f"{types.capitalize()} loaded ! Importing {data_name[:-4]}...")
        return pl.read_csv(datas, separator=sep, ignore_errors=True)
    else:
        raise ValueError(
            f"{types} not recognize please use : [ pandas | polars ] ")


def order_and_rename(
    df: pl.DataFrame,
    og_col: list,
    new_col_name: list
) -> pd.DataFrame:
    """
    Ordonne et renomme les colonnes d'un DataFrame.

    Cette fonction prend un DataFrame, une liste de noms de colonnes originaux et une liste de nouveaux noms de colonnes.
    Elle renvoie un DataFrame avec les colonnes r√©organis√©es et renomm√©es.

    Parameters
    ----------
    df : pl.DataFrame
        Le DataFrame d'entr√©e sur lequel effectuer l'op√©ration de r√©organisation et de renommage.
    og_col : list
        Une liste de cha√Ænes de caract√®res repr√©sentant les noms de colonnes originaux dans le DataFrame.
    new_col_name : list
        Une liste de cha√Ænes de caract√®res repr√©sentant les nouveaux noms de colonnes pour le DataFrame.

    Returns
    -------
    pl.DataFrame
        Un nouveau DataFrame avec les colonnes r√©organis√©es et renomm√©es.

    Notes
    -----
    Les listes og_col et new_col_name doivent avoir la m√™me longueur. Chaque √©l√©ment de og_col est associ√© √† l'√©l√©ment correspondant
    dans new_col_name pour le renommage.
    """
    return df.select(
        [
            pl.col(old).alias(new) for
            old, new in zip(og_col, new_col_name)
        ]
    )

def order_and_rename_pandas(
    df: pd.DataFrame,
    og_col: list,
    new_col_name: list
) -> pd.DataFrame:
    """
    Ordonne et renomme les colonnes d'un DataFrame pandas.

    Param√®tres
    ----------
    df : pd.DataFrame
        DataFrame d'entr√©e sur lequel effectuer les op√©rations.
    og_col : list
        Liste des noms originaux des colonnes √† renommer.
    new_col_name : list
        Liste des nouveaux noms de colonnes.

    Retourne
    -------
    pd.DataFrame
        DataFrame avec les colonnes r√©organis√©es et renomm√©es.

    Notes
    -----
    Les listes og_col et new_col_name doivent avoir la m√™me longueur.
    """
    rename_dict = {old: new for old, new in zip(og_col, new_col_name)}
    df.rename(columns=rename_dict, inplace=True)
    return df


def col_to_keep(
    datasets: str
) -> list:
    """
    Renvoie une liste des noms de colonnes √† conserver dans un dataframe en fonction du type de donn√©es.

    Parameters
    ----------
    datasets : str
        Le type de donn√©es pour lequel obtenir les noms de colonnes.
        Les valeurs valides sont "movies", "actors",
        "directors", "actors_movies" et "directors_movies".

    Returns
    -------
    list
        Une liste des noms de colonnes √† conserver.

    Raises
    ------
    KeyError
        Si le type de donn√©es n'est pas valide.
    """
    if datasets == "movies":
        return [
            "tconst",
            "primaryTitle",
            "startYear",
            "runtimeMinutes",
            "genres",
            "averageRating",
            "numVotes",
        ]
    if datasets in ["actors", "directors"]:
        return [
            # "titre_id",
            # "titre_str",
            # "titre_date_sortie",
            # "titre_duree",
            # "titre_genres",
            # "rating_avg",
            # "rating_votes",
            "nconst", # name_basics             "person_id",
            "primaryName", # name_basics        "person_name",
            "birthYear", # name_basics          "person_birthdate",
            "category", # name_basics           "person_job",
            # "characters", # name_basicsa        "person_role",
            # "ordering", # name_basics           "person_index",
            "knownForTitles", # name_basics     "person_film",
            "ordering", # name_basics     "person_film",
        ]
    if datasets in ["actors_movies", "directors_movies"]:
        return [
            "titre_id",
            "titre_str",
            "titre_date_sortie",
            "titre_duree",
            "titre_genres",
            "rating_avg",
            "rating_votes",
            "original_language",
            "original_title",
            "popularity",
            "production_countries",
            "revenue",
            "spoken_languages",
            "status",
            "region",
            "cuts",
            "nconst", # name_basics             "person_id",
            "primaryName", # name_basics        "person_name",
            "birthYear", # name_basics          "person_birthdate",
            "category", # name_basics           "person_job",
            "characters", # name_basicsa        "person_role",
            "knownForTitles", # name_basics     "person_film",
            "ordering", # name_basics           "person_film",
        ]
    else:
        raise KeyError(f"{datasets} n'est pas valide!")


def col_renaming(
    datasets: str
) -> list:
    """
    Fonction pour renvoyer une liste de noms de colonnes √† modifier dans un dataframe.

    Param√®tres
    ----------
    datasets : str
        Le nom du dataset pour lequel la liste des noms de colonnes est requise.

    Retourne
    -------
    list
        Une liste de noms de colonnes √† modifier.
        Si le dataset est "movies", la liste contient les noms de colonnes
        sp√©cifiques √† ce dataset.
        Si le dataset est "actors_movies" ou "directors_movies", la liste contient les noms de
        colonnes sp√©cifiques √† ces datasets. Si le dataset n'est pas reconnu, une KeyError est lev√©e.

    L√®ve
    -----
    KeyError
        Si le nom du dataset n'est pas reconnu.
    """
    if datasets == "movies":
        return [
            "titre_id",
            "titre_str",
            "titre_date_sortie",
            "titre_duree",
            "titre_genres",
            "rating_avg",
            "rating_votes",
        ]
    if datasets in ["actors_movies", "directors_movies"]:
        return [
            "titre_id",
            "titre_str",
            "titre_date_sortie",
            "titre_duree",
            "titre_genres",
            "rating_avg",
            "rating_votes",
            "original_language",
            "original_title",
            "popularity",
            "production_countries",
            "revenue",
            "spoken_languages",
            "status",
            "region",
            "cuts",
            "person_id",
            "person_name",
            "person_birthdate",
            "person_job",
            "person_role",
            "person_film",
            "person_index",
        ]
    else:
        raise KeyError(f"{datasets} n'est pas valide!")


def bins_generator(max_date_df: int) -> tuple:
    """
    G√©n√®re des intervalles de temps et leurs noms correspondants.

    Param√®tres
    ----------
    max_date_df : int
        L'ann√©e maximale √† consid√©rer pour la g√©n√©ration des intervalles.

    Retourne
    -------
    tuple
        Un tuple contenant deux listes. La premi√®re liste contient les limites des intervalles de temps.
        La deuxi√®me liste contient les noms correspondants √† ces intervalles.

    """
    bins = [0, 1900]
    names = ["<1900"]

    for year in range(1900, max_date_df, 10):
        bins.append(year + 9)
        names.append(f"{year}-{year+9}")

    if max_date_df >= bins[-2]:
        names[-1] = f">{names[-1][:4]}"

    return bins, names


def create_main_movie_dataframe(
    sets: dict,
) -> pl.DataFrame:
    """
    Cr√©e un DataFrame principal pour les films √† partir d'un ensemble de donn√©es sp√©cifi√©.

    Cette fonction importe d'abord les ensembles de donn√©es, filtre les films, nettoie les films pornographiques,
    puis convertit le DataFrame en Polars pour fusionner.

    Param√®tres
    ----------
    sets : dict
        Un dictionnaire contenant les ensembles de donn√©es √† importer. La cl√© doit √™tre "title_basics".

    Renvoie
    -------
    pl.DataFrame
        Un DataFrame Polars contenant les informations des films nettoy√©s.

    """
    first_df = import_datasets(
        sets["title_basics"],
        "polars",
        sep = "\t"
    )
    movies = first_df.filter(
        first_df["titleType"] == "movie"
    )
    # Convert into Pandas df to clean porn movies
    moviesO = movies.to_pandas()

    # Clean porn movies
    movies = clean.clean_porn(moviesO, columns_name="genres")
    logging.info(f"Cleaned : {len(moviesO) - len(movies)} rows")

    # Convert back into Polars to proceed merging
    movies = pl.from_pandas(movies)
    return movies


def join_dataframes(
    data1: pl.DataFrame,
    data2: pl.DataFrame,
    left: str = 'tconst',
    right: str = 'tconst',
) -> pl.DataFrame:
    """
    Fusionne deux dataframes sur la base des colonnes sp√©cifi√©es.

    Parameters
    ----------
    data1 : pl.DataFrame
        Le premier dataframe √† fusionner.
    data2 : pl.DataFrame
        Le deuxi√®me dataframe √† fusionner.
    left : str, optional
        Le nom de la colonne sur laquelle effectuer la fusion dans le premier dataframe.
        Par d√©faut, c'est 'tconst'.
    right : str, optional
        Le nom de la colonne sur laquelle effectuer la fusion dans le deuxi√®me dataframe.
        Par d√©faut, c'est 'tconst'.

    Returns
    -------
    pl.DataFrame
        Un nouveau dataframe qui est le r√©sultat de la fusion des deux dataframes d'entr√©e.
    """
    return data1.join(data2, left_on=left, right_on=right)


def filter_before_join(
    data: pl.DataFrame,
    filter_list: list,
    column_to_filter: str = "category"
) -> pl.DataFrame:
    """
    Filtre les donn√©es d'un DataFrame en fonction d'une liste de filtres et d'une colonne sp√©cifique.

    Parameters
    ----------
    data : pl.DataFrame
        Le DataFrame √† filtrer.
    filter_list : list
        La liste des valeurs √† utiliser pour le filtrage.
    column_to_filter : str, optional
        Le nom de la colonne √† filtrer. Par d√©faut, il s'agit de "category".

    Returns
    -------
    pl.DataFrame
        Le DataFrame filtr√©.
    """
    condi = (data[column_to_filter].is_in(filter_list))
    return data.filter(condi)


def single_base_transform(
    datas1: pl.DataFrame,
    datas2: pl.DataFrame,
    name: str = "movies",
    folder_name: str = "big_dataframe",
    left_on: str = "tconst",
    right_on: str = "tconst",
) -> pl.DataFrame:
    """
    Effectue une transformation de base unique sur deux DataFrames pandas, les joint,
    les renomme et les enregistre en CSV.

    Param√®tres
    ----------
    datas1 : pandas.DataFrame
        Premier DataFrame √† transformer.
    datas2 : pandas.DataFrame
        Deuxi√®me DataFrame √† transformer.
    name : str, optionnel
        Nom de la transformation, par d√©faut "movies".
    folder_name : str, optionnel
        Nom du dossier o√π le fichier CSV sera enregistr√©, par d√©faut "big_dataframe".
    left_on : str, optionnel
        Nom de la colonne sur laquelle effectuer la jointure √† gauche, par d√©faut "tconst".
    right_on : str, optionnel
        Nom de la colonne sur laquelle effectuer la jointure √† droite, par d√©faut "tconst".

    Retourne
    -------
    pandas.DataFrame
        DataFrame transform√©, joint, renomm√© et enregistr√© en CSV.

    """
    logging.info(f"Joining {name} dataframes...")
    df_ = join_dataframes(
        datas1,
        datas2,
        left_on,
        right_on
    )
    logging.info(f"Renaming {name} columns...")
    df = order_and_rename(
        df_,
        col_to_keep(name),
        col_renaming(name)
    )
    # if not os.path.exists(folder_name):
    #     os.makedirs(folder_name)

    # df.write_parquet(f"{folder_name}/{name}.parquet")
    return df


def double_base_transform(
    datas1: pl.DataFrame,
    datas2: pl.DataFrame,
    datas3: pl.DataFrame,
    name: str = "actors",
    filter_list: list = [],
    folder_name: str = "big_dataframe",
    left1: str = "tconst",
    right1: str = "tconst",
    left2: str = "nconst",
    right2: str = "nconst",
) -> pl.DataFrame:
    """
    Effectue une double transformation de base sur les donn√©es fournies.

    Param√®tres
    ----------
    datas1 : pl.DataFrame
        Premier jeu de donn√©es √† transformer.
    datas2 : pl.DataFrame
        Deuxi√®me jeu de donn√©es √† transformer.
    datas3 : pl.DataFrame
        Troisi√®me jeu de donn√©es √† transformer.
    name : str, optionnel
        Nom associ√© aux donn√©es, par d√©faut "actors".
    filter_list : list, optionnel
        Liste des filtres √† appliquer avant la jointure, par d√©faut [].
    folder_name : str, optionnel
        Nom du dossier o√π les donn√©es transform√©es seront stock√©es, par d√©faut "big_dataframe".
    left1 : str, optionnel
        Nom de la colonne √† utiliser comme cl√© gauche pour la premi√®re jointure, par d√©faut "tconst".
    right1 : str, optionnel
        Nom de la colonne √† utiliser comme cl√© droite pour la premi√®re jointure, par d√©faut "tconst".
    left2 : str, optionnel
        Nom de la colonne √† utiliser comme cl√© gauche pour la deuxi√®me jointure, par d√©faut "nconst".
    right2 : str, optionnel
        Nom de la colonne √† utiliser comme cl√© droite pour la deuxi√®me jointure, par d√©faut "nconst".

    Retourne
    -------
    pl.DataFrame
        DataFrame r√©sultant de la double transformation de base.
    """
    logging.info(f"Joining {name} dataframes...")
    df__ = join_dataframes(
        datas1,
        datas2,
        left1,
        right1
    )

    df_ = filter_before_join(
        df__, filter_list, "category"
    )

    df = single_base_transform(
        df_,
        datas3,
        name,
        folder_name,
        left2,
        right2
    )
    return df



def decode_clean(
    serie: pd.Series
) -> str:
    """
    D√©code et nettoie une s√©rie pandas.

    Cette fonction prend une s√©rie pandas en entr√©e et retourne une cha√Æne de caract√®res
    o√π certains caract√®res sp√©cifiques sont supprim√©s. Les caract√®res supprim√©s sont :
    "[", "]", "'", " ", et '"'.

    Parameters
    ----------
    serie : pd.Series
        La s√©rie pandas √† d√©coder et nettoyer.

    Returns
    -------
    str
        La s√©rie pandas d√©cod√©e et nettoy√©e, sous forme de cha√Æne de caract√®res.
    """
    return (
        serie.replace("[", "")
            .replace("]", "")
            .replace("'", "")
            .replace(" ", "")
            .replace('"', "")
        )


def decode_clean_actors(
    serie: pd.Series
) -> str:
    """
    D√©code et nettoie une s√©rie d'acteurs.

    Cette fonction prend une s√©rie pandas en entr√©e, supprime tous les caract√®res non d√©sir√©s tels que les crochets, les guillemets doubles et simples, et renvoie la s√©rie nettoy√©e sous forme de cha√Æne de caract√®res.

    Param√®tres
    ----------
    serie : pd.Series
        La s√©rie pandas contenant les noms d'acteurs √† nettoyer.

    Retourne
    -------
    str
        La s√©rie nettoy√©e sous forme de cha√Æne de caract√®res.

    """
    return (
        serie.replace("[", "")
            .replace("]", "")
            .replace('"', "")
            .replace("'", "")
        )

def clean_overview(
    text: str
):
    text = text.lower()
    text = re.sub(r'[^a-z]', ' ', text)
    words = text.split()
    words = [word for word in words if word not in stopwords.words('english')]
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(word) for word in words]
    return ' '.join(words)


def full_lower(
    text: str
):
    return text.replace(" ", "")

def color(text: str, color: str = None):
    if color and color.startswith("#"):
        return f"{fg(color)}{text}{attr(0)}"
    elif color == 'red':
        return f"{fg(1)}{text}{attr(0)}"
    elif color == 'green':
        return f"{fg(2)}{text}{attr(0)}"
    elif color == 'yellow':
        return f"{fg(3)}{text}{attr(0)}"
    elif color == 'blue':
        return f"{fg(4)}{text}{attr(0)}"
    else:
        return text